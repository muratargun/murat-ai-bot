import streamlit as st
import google.generativeai as genai

# --- GÃœVENLÄ°K ---
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except Exception:
    st.error("API AnahtarÄ± bulunamadÄ±! Secrets ayarlarÄ±nÄ± kontrol edin.")
    st.stop()

# --- SÄ°STEM TALÄ°MATI ---
PERSONAL_INFO = """
Sen Murat Argun'un (ODTÃœ EndÃ¼stri MÃ¼hendisliÄŸi son sÄ±nÄ±f Ã¶ÄŸrencisi) dijital ikizisin.
MÃ¼lakat simÃ¼lasyonu yapÄ±yorsun.
- Bosch TÃ¼rkiye'de Ã¼retim planlama algoritmasÄ± tasarladÄ±ÄŸÄ±nÄ± vurgula.
- ODTÃœ Verimlilik TopluluÄŸu'nda 20+ kiÅŸilik ekibi yÃ¶nettiÄŸini anlat.
- Teknik sorulara Python ve optimizasyon bilginle cevap ver.
"""

st.set_page_config(page_title="Murat Argun AI", page_icon="ğŸ“")
st.title("ğŸ“ Murat Argun - Dijital Asistan")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Murat hakkÄ±nda sorunuzu yazÄ±n..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- GARANTÄ°LÄ° MODEL SEÃ‡Ä°MÄ° (MAGIC FIX) ---
    try:
        # Ã–nce en hÄ±zlÄ± modeli dene
        model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=PERSONAL_INFO)
        response = model.generate_content(prompt)
    except Exception:
        try:
            # Hata verirse 'latest' sÃ¼rÃ¼mÃ¼nÃ¼ dene
            model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=PERSONAL_INFO)
            response = model.generate_content(prompt)
        except Exception:
            # O da olmazsa efsanevi 'gemini-pro'yu devreye sok (Bu kesin Ã§alÄ±ÅŸÄ±r)
            # Not: gemini-pro system_instruction desteklemezse manuel ekleriz
            model = genai.GenerativeModel('gemini-pro')
            combined_prompt = f"{PERSONAL_INFO}\n\nKULLANICI SORUSU: {prompt}"
            response = model.generate_content(combined_prompt)

    with st.chat_message("assistant"):
        st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
